{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "State Regularized RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvxPZmYKh7EgnoQHwgm0Br",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelly-hateva/tardis/blob/master/notebooks/State_Regularized_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y0Pyq0G0A4W",
        "colab_type": "text"
      },
      "source": [
        "Prerequisities: Access data in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvCTwouDz-zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "MOUNT_POINT = \"/content/drive/\"\n",
        "DATA_DIR = MOUNT_POINT + \"My Drive/Colab Notebooks/Thesis-Data\"\n",
        "MODELS_DIR = MOUNT_POINT + \"My Drive/Colab Notebooks/Thesis-Models\"\n",
        "drive.mount(MOUNT_POINT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQZ5n1R0aWe",
        "colab_type": "text"
      },
      "source": [
        "Import libraries, set random seed and device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u56lsr5U0W7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import copy\n",
        "\n",
        "import numpy\n",
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "\n",
        "def seed_torch(seed=666):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  numpy.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_torch()\n",
        "\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIdpnf0yerS5",
        "colab_type": "text"
      },
      "source": [
        "State Regularized RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ed6ar_Jc8dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SRRNN(nn.Module):\n",
        "\n",
        "  r\"\"\" https://arxiv.org/pdf/1901.08817.pdf\n",
        "       https://github.com/deepsemantic/sr-rnns\n",
        "  Applies a single-layer State Regularized RNN to an input sequence.\n",
        "\n",
        "  If :attr:`mode` is ``'rnn'``, then for each element in the input sequence computes the function\n",
        "\n",
        "    .. math::\n",
        "        h_t' = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
        "\n",
        "    where :math:`x_t` is the input at time `t`, :math:`h_{(t-1)}` is the hidden state\n",
        "    at time `t-1` or the initial hidden state at time `0`.\n",
        "    If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.\n",
        "\n",
        "  If :attr:`mode` is ``'gru'``, then for each element in the input sequence computes the function\n",
        "\n",
        "    .. math::\n",
        "      \\begin{array}{ll} \\\\\n",
        "        r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
        "        z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
        "        n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
        "        h_t' = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
        "      \\end{array}\n",
        "\n",
        "    where :math:`x_t` is the input at time `t`, :math:`h_{(t-1)}` is the hidden state\n",
        "    at time `t-1` or the initial hidden state at time `0`.\n",
        "    :math:`r_t`, :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n",
        "    :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
        "\n",
        "  In both modes, if :attr:`number_of_states` is ``None``, then the hidden state\n",
        "  at time `t` :math:`h_t` equals :math:`h_t'`. \n",
        "\n",
        "  Otherwise,\n",
        "\n",
        "    .. math::\n",
        "      \\begin{array}{ll} \\\\\n",
        "        \\alpha_{i} = \\frac{\\exp(- \\Vert{h_t' - s_i}\\Vert)}{\\sum_{i=1}^{k} \\exp(- \\Vert{h_t' - s_i}\\Vert)}\n",
        "        h_t = {\\sum_{i=1}^{k} \\alpha_{i} s_i}\n",
        "      \\end{array}\n",
        "\n",
        "    where :math:`\\{s_1, s_2, ..., s_k\\}` are the k learnable states. \n",
        "    :math:`\\alpha_{i}` is the probability of the RNN to transition to state i\n",
        "    given the vector :math:`h_t'` for which we write :math:`p_{h_t'}(i) = \\alpha_{i}`\n",
        "\n",
        "    Args:\n",
        "        input_size: The number of expected features in the input `x`\n",
        "        hidden_size: The number of features in the hidden state `h`\n",
        "        mode: The RNN mode to use.\n",
        "          Can be either ``'rnn'`` or ``'gru'``. Default: ``'rnn'``\n",
        "        nonlinearity: The non-linearity to use if :attr:`mode` is ``'rnn'``.\n",
        "          Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
        "        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
        "            Default: ``True``\n",
        "        number_of_states: The number of learnable finite states.\n",
        "          If ``None`` then the stohastic component is not used. Default: ``None``\n",
        "\n",
        "    Inputs: input, h_0\n",
        "        - **input** of shape `(batch, seq_len, input_size)`:\n",
        "          tensor containing the features of the input sequence.\n",
        "          The input can also be a packed variable length sequence.\n",
        "          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
        "          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
        "        - **h_0** of shape `(batch, hidden_size)`: tensor\n",
        "          containing the initial hidden state for each element in the batch.\n",
        "\n",
        "          If `h_0` is not provided, it defaults to zero.\n",
        "\n",
        "    Outputs: output, h_n\n",
        "        - **output** of shape `(batch, seq_len, hidden_size)`: tensor\n",
        "          containing the output features `(h_t)` from the RNN for each `t`.\n",
        "          If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
        "          given as the input, the output will also be a packed sequence.\n",
        "        - **h_n** of shape `(batch, hidden_size)`: tensor\n",
        "          containing the hidden state for `t = seq_len`.\n",
        "\n",
        "    Attributes:\n",
        "        If :attr:`mode` is ``'rnn'``\n",
        "          weight_ih: the learnable input-hidden weights,\n",
        "              of shape `(hidden_size, input_size)`\n",
        "          weight_hh: the learnable hidden-hidden weights,\n",
        "              of shape `(hidden_size, hidden_size)`\n",
        "          bias_ih: the learnable input-hidden bias,\n",
        "              of shape `(hidden_size)`\n",
        "          bias_hh: the learnable hidden-hidden bias,\n",
        "              of shape `(hidden_size)`\n",
        "        If :attr:`mode` is ``'gru'``\n",
        "          weight_ih : the learnable input-hidden weights\n",
        "              (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)`\n",
        "          weight_hh : the learnable hidden-hidden weights\n",
        "              (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n",
        "          bias_ih : the learnable input-hidden bias\n",
        "              (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n",
        "          bias_hh : the learnable hidden-hidden bias\n",
        "              (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n",
        "        states: the learnable finite number of states, of shape\n",
        "            `(number_of_states, hidden_size)\n",
        "\n",
        "    .. note::\n",
        "        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
        "        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
        "\n",
        "    Examples::\n",
        "        >>> rnn = SRRNN(10, 20)\n",
        "        >>> input = torch.randn(6, 3, 10)\n",
        "        >>> h_0 = torch.randn(6, 20)\n",
        "        >>> output, h_n = rnn(input, h_0)\n",
        "    \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "    self, input_size, hidden_size, bias=True, mode='rnn', nonlinearity='tanh',\n",
        "    number_of_states=None, temperature=1.00\n",
        "  ):\n",
        "    super(SRRNN, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    if mode == 'rnn':\n",
        "      self.rnn_cell = nn.RNNCell(\n",
        "        input_size, hidden_size, bias=bias, nonlinearity=nonlinearity\n",
        "      )\n",
        "    elif mode == 'gru':\n",
        "      self.rnn_cell = nn.GRUCell(\n",
        "        input_size, hidden_size, bias=bias\n",
        "      )\n",
        "    else:\n",
        "      raise ValueError(\"Unknown model '{}'\".format(mode))\n",
        "\n",
        "    self.stohastic_component = False\n",
        "\n",
        "    if number_of_states:\n",
        "      self.stohastic_component = True\n",
        "      self.number_of_states = number_of_states\n",
        "\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "      self.states = nn.Parameter(\n",
        "        torch.Tensor(\n",
        "            self.number_of_states, hidden_size\n",
        "        )\n",
        "      )\n",
        "      self.temperature = temperature\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    # for hh, ih in zip(\n",
        "    #   self.rnn_cell.weight_hh.chunk(self.number_of_gates, 0),\n",
        "    #   self.rnn_cell.weight_ih.chunk(self.number_of_gates, 0)\n",
        "    # ):\n",
        "    #   nn.init.orthogonal_(hh)\n",
        "    #   nn.init.orthogonal_(ih)\n",
        "\n",
        "    # if self.bias:\n",
        "    #   nn.init.zeros_(self.rnn_cell.bias_ih)\n",
        "    #   nn.init.zeros_(self.rnn_cell.bias_hh)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      nn.init.uniform_(self.states, a=-0.1, b=0.1)\n",
        "\n",
        "  def extra_repr(self):\n",
        "    s = ''\n",
        "    if 'number_of_states' in self.__dict__:\n",
        "      s = 'number_of_states={number_of_states}'\n",
        "      if 'temperature' in self.__dict__ and self.temperature != 1.00:\n",
        "        s += ', temperature={temperature}'\n",
        "\n",
        "    return s.format(**self.__dict__)\n",
        "\n",
        "  def permute_hidden(self, hidden, permutation, dim=0):\n",
        "    if permutation is None:\n",
        "      return hidden\n",
        "    return hidden.index_select(dim, permutation)\n",
        "\n",
        "  def forward(self, input, h_0=None):\n",
        "    orig_input = input\n",
        "\n",
        "    if isinstance(orig_input, nn.utils.rnn.PackedSequence):\n",
        "      input, batch_sizes, sorted_indices, unsorted_indices = input\n",
        "      max_batch_size = int(batch_sizes[0])\n",
        "    else:\n",
        "      max_batch_size, sorted_indices = input.size(0), None\n",
        "\n",
        "    if h_0 is None:\n",
        "      h_0 = torch.zeros(\n",
        "        max_batch_size, self.hidden_size, dtype=input.dtype, device=input.device\n",
        "      )\n",
        "      #  h_0 = self.states[0].expand(max_batch_size, -1)\n",
        "    else:\n",
        "      # Each batch of the hidden state should match the input sequence that\n",
        "      # the user believes he/she is passing in.\n",
        "      h_0 = self.permute_hidden(h_0, sorted_indices)\n",
        "\n",
        "    if isinstance(orig_input, nn.utils.rnn.PackedSequence):\n",
        "      output, hidden, transition_probabilities = self.forward_packed(input, batch_sizes, h_0)\n",
        "\n",
        "      if self.stohastic_component:\n",
        "        transition_probabilities = nn.utils.rnn.PackedSequence(\n",
        "          transition_probabilities, batch_sizes, sorted_indices, unsorted_indices\n",
        "        )\n",
        "\n",
        "      hidden = self.permute_hidden(hidden, unsorted_indices)\n",
        "      output = nn.utils.rnn.PackedSequence(\n",
        "        output, batch_sizes, sorted_indices, unsorted_indices\n",
        "      )\n",
        "\n",
        "      return output, hidden, transition_probabilities\n",
        "\n",
        "    return self.forward_tensor(input, h_0)\n",
        "\n",
        "  def forward_tensor(self, input, h_0):\n",
        "    output, h_t = [], h_0\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      transition_probabilities = []\n",
        "\n",
        "    for t in range(input.size(1)):\n",
        "      result = self.forward_impl(input[:,t,:], h_t)\n",
        "      if self.stohastic_component:\n",
        "        transition_probs, h_t = result\n",
        "        transition_probabilities.append(transition_probs)\n",
        "      else:\n",
        "        h_t = result\n",
        "      output.append(h_t)\n",
        "\n",
        "    output = torch.stack(output).permute(1, 0, 2)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      return output, h_t, torch.stack(transition_probabilities).permute(1, 0, 2)\n",
        "    return output, h_t, None\n",
        "\n",
        "  def forward_packed(self, input, batch_sizes, h_0):\n",
        "    output, h_n, t, h_t = [], [], 0, h_0\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      transition_probabilities = []\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "      batch_size = int(batch_size)\n",
        "\n",
        "      h_t, h_n_ = h_t[:batch_size], h_t[batch_size:]\n",
        "      h_n.append(h_n_)\n",
        "      result = self.forward_impl(input[t : t + batch_size], h_t)\n",
        "\n",
        "      if self.stohastic_component:\n",
        "        transition_probs, h_t = result\n",
        "        transition_probabilities.append(transition_probs)\n",
        "      else:\n",
        "        h_t = result\n",
        "\n",
        "      output.append(h_t)\n",
        "      t += batch_size\n",
        "\n",
        "    h_n.append(h_t)\n",
        "    h_n.reverse()\n",
        "\n",
        "    output, h_n = torch.cat(output), torch.cat(h_n)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      return output, h_n, torch.cat(transition_probabilities)\n",
        "    return output, h_n, None\n",
        "\n",
        "  def forward_impl(self, input, h_t):\n",
        "    h_t_ = self.rnn_cell(input, h_t)\n",
        "    if self.stohastic_component:\n",
        "      transition_probs = self.softmax(\n",
        "        (self.states * h_t_.unsqueeze(1)).sum(-1)\n",
        "      )\n",
        "      return transition_probs, torch.matmul(transition_probs, self.states)\n",
        "    return h_t_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnLM-uoyjSDJ",
        "colab_type": "text"
      },
      "source": [
        "Test for pack padded sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndaEv8LjTB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  for _ in range(1024):\n",
        "\n",
        "    batch_size = random.randint(1, 15)\n",
        "    seq_length = random.randint(1, 15)\n",
        "    input_size = random.randint(1, 5)\n",
        "    hidden_size = random.randint(1, 5)\n",
        "    bias = bool(random.getrandbits(1))\n",
        "    nonlinearity = random.choice(['tanh', 'relu'])\n",
        "    mode = random.choice(['rnn', 'gru'])\n",
        "    number_of_states = random.randint(1, 15)\n",
        "    temperature = random.choice([1.00, 0.5, 0.1])\n",
        "\n",
        "    input = torch.rand(batch_size, seq_length, input_size).to(device)\n",
        "    h_0 = torch.rand(batch_size, hidden_size).to(device)\n",
        "\n",
        "    lengths = torch.randint(1, seq_length + 1, (batch_size,)).to(device)\n",
        "    packed_sequence = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "      input, lengths, batch_first=True, enforce_sorted=False\n",
        "    )\n",
        "\n",
        "    # without stohastic component\n",
        "    model = SRRNN(\n",
        "      input_size, hidden_size, bias=bias, mode=mode, nonlinearity=nonlinearity\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    output, h_n, _ = model(input, h_0)\n",
        "\n",
        "    assert h_n.size() == (batch_size, hidden_size)\n",
        "    assert output.size() == (batch_size, seq_length, hidden_size)\n",
        "\n",
        "    output_packed, h_n_packed, _ = model(packed_sequence, h_0)\n",
        "\n",
        "    assert h_n_packed.size() == (batch_size, hidden_size)\n",
        "    assert output_packed.data.size() == (lengths.sum().item(), hidden_size)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      assert torch.allclose(h_n_packed[i,:], output[i, lengths[i].item() - 1, :], atol=1e-07)\n",
        "\n",
        "    # with stohastic component\n",
        "    model = SRRNN(\n",
        "      input_size, hidden_size, bias=bias, mode=mode, nonlinearity=nonlinearity,\n",
        "      number_of_states=number_of_states, temperature=temperature\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    output, h_n, transition_probabilities = model(input, h_0)\n",
        "\n",
        "    assert h_n.size() == (batch_size, hidden_size)\n",
        "    assert output.size() == (batch_size, seq_length, hidden_size)\n",
        "    assert transition_probabilities.size() == (batch_size, seq_length, number_of_states)\n",
        "\n",
        "    output_packed, h_n_packed, transition_probabilities_packed = model(packed_sequence, h_0)\n",
        "\n",
        "    assert h_n_packed.size() == (batch_size, hidden_size)\n",
        "    assert output_packed.data.size() == (lengths.sum().item(), hidden_size)\n",
        "    assert transition_probabilities_packed.data.size() == (lengths.sum().item(), number_of_states)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      assert torch.allclose(h_n_packed[i,:], output[i, lengths[i].item() - 1, :], atol=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAaRQ6-0LOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLNN(nn.Module):\n",
        "\n",
        "  def __init__(self, params):\n",
        "    super(NLNN, self).__init__()\n",
        "\n",
        "    # + 1 because of the padding with 0s\n",
        "    num_embeddings = params['num_embeddings'] + 1\n",
        "\n",
        "    if 'embedding_dim' in params:\n",
        "      embedding_dim = params['embedding_dim']\n",
        "      self.embeddings = nn.Embedding(\n",
        "        num_embeddings,\n",
        "        embedding_dim,\n",
        "        padding_idx = 0\n",
        "      )\n",
        "      input_size = embedding_dim\n",
        "    else:\n",
        "      # one hot encoding\n",
        "      self.embeddings = nn.Embedding(\n",
        "          num_embeddings,\n",
        "          num_embeddings,\n",
        "          padding_idx = 0\n",
        "      )\n",
        "      nn.init.eye_(self.embeddings.weight.data)\n",
        "      self.embeddings.weight.requires_grad = False\n",
        "      input_size = num_embeddings\n",
        "\n",
        "    if 'number_of_states' in params:\n",
        "      self.rnn = SRRNN(\n",
        "        input_size, params['hidden_size'], bias=params['bias'],\n",
        "        mode=params['mode'], nonlinearity=params['nonlinearity'],\n",
        "        number_of_states=params['number_of_states'],\n",
        "        temperature=params['temperature']\n",
        "      )\n",
        "    else:\n",
        "      self.rnn = SRRNN(\n",
        "        input_size, params['hidden_size'], bias=params['bias'],\n",
        "        mode=params['mode'], nonlinearity=params['nonlinearity']\n",
        "      )\n",
        "\n",
        "    self.linear = nn.Linear(\n",
        "      in_features=params['hidden_size'], out_features=2, bias=True\n",
        "    )\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x, length, return_probabilities=False):\n",
        "    embedding_output = self.embeddings(x)\n",
        "    packed_sequence = nn.utils.rnn.pack_padded_sequence(\n",
        "      embedding_output, length, batch_first=True, enforce_sorted=False\n",
        "    )\n",
        "    rnn_output, h_n, transition_probs = self.rnn(packed_sequence)\n",
        "    linear_output = self.linear(h_n)\n",
        "    softmax_output = self.softmax(linear_output)\n",
        "\n",
        "    if return_probabilities:\n",
        "      return softmax_output, transition_probs\n",
        "\n",
        "    return softmax_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOiy1Kys02Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLDataset(utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, dataset):\n",
        "    data, length, labels = dataset\n",
        "    self.data = torch.tensor(data).long().to(device)\n",
        "    self.length = torch.tensor(length).long().to(device)\n",
        "    self.labels = torch.tensor(labels).long().to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\n",
        "      'x': self.data[idx],\n",
        "      'length': self.length[idx],\n",
        "      'y': self.labels[idx]\n",
        "    }\n",
        "\n",
        "def load_data(filename_data, filename_length, filename_labels):\n",
        "  return numpy.load(filename_data, allow_pickle=True), \\\n",
        "    numpy.load(filename_length, allow_pickle=True), \\\n",
        "    numpy.load(filename_labels, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUX8FKwB1SyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __evaluate(predictions, labels):\n",
        "  assert(len(predictions) == len(labels))\n",
        "\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    if label == 1:\n",
        "      if prediction == 1:\n",
        "        tp += 1\n",
        "      else:\n",
        "        fn += 1\n",
        "    else:\n",
        "      if prediction == 1:\n",
        "        fp += 1\n",
        "      else:\n",
        "        tn += 1\n",
        "\n",
        "  if tp == 0:\n",
        "    if fn == 0 and fp == 0:\n",
        "      pr, r, f1 = 1, 1, 1\n",
        "    else:\n",
        "      pr, r, f1 = 0, 0, 0\n",
        "  else:\n",
        "    pr = tp / (tp + fp)\n",
        "    r = tp / (tp + fn)\n",
        "    f1 = 2 * ((pr * r) / (pr + r))\n",
        "\n",
        "  accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "  return tp, tn, fp, fn, pr, r, f1, accuracy\n",
        "\n",
        "def _evaluate(data_loader, model):\n",
        "  model.eval()\n",
        "\n",
        "  predictions, labels = [], []\n",
        "\n",
        "  for data in data_loader:\n",
        "    result = model(data['x'], data['length'])\n",
        "    argmax = result.argmax(dim=1).cpu().numpy()\n",
        "    predictions.extend(list(argmax))\n",
        "    labels.extend(list(data['y'].cpu().numpy()))\n",
        "\n",
        "  return __evaluate(predictions, labels)\n",
        "\n",
        "def evaluate_model(data_loader, model, set_name):\n",
        "  tp, tn, fp, fn, pr, r, f1, acc = _evaluate(data_loader, model)\n",
        "  print(\"{} : TP : {} TN : {} FP : {} FN : {} Pr : {} R : {} F1: {} ACC : {} \".format(\n",
        "    set_name, tp, tn, fp, fn, pr, r, f1, acc\n",
        "  ))\n",
        "\n",
        "def model_summary(model):\n",
        "  print (model)\n",
        "  print()\n",
        "\n",
        "  print(\"Trainable parameters:\")\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      print (\" \", name)\n",
        "  print()\n",
        "\n",
        "  number_of_trainable_parameters = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        "  )\n",
        "  print(\"Number of trainable parameters {0:,}\".format(\n",
        "    number_of_trainable_parameters\n",
        "  ))\n",
        "  print()\n",
        "\n",
        "def train_model(\n",
        "    model, params=None, params_path=None, model_path=None,\n",
        "    train_loader=None, dev_loader=None\n",
        "):\n",
        "  model.to(device)\n",
        "  model_summary(model)\n",
        "\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  best_dev_accuracy, best_state_dict, best_epoch = 0, dict(), -1\n",
        "\n",
        "  # first_batch = next(iter(train_loader))\n",
        "  # print (first_batch)\n",
        "\n",
        "  for epoch in range(params['num_epochs']):\n",
        "    print('Epoch {}/{} : '.format(epoch, params['num_epochs']))\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train() # set the model to training mode\n",
        "    #for data in [first_batch] * 1:\n",
        "    for data in train_loader:\n",
        "      model.zero_grad()\n",
        "      predictions = model(data['x'], data['length'])\n",
        "      batch_loss = loss_function(predictions, data['y'])\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    # _, _, _, _, _, _, _, dev_accuracy = _evaluate(dev_loader, model)\n",
        "\n",
        "    # if dev_accuracy > best_dev_accuracy:\n",
        "    #   best_dev_accuracy = dev_accuracy\n",
        "    #   best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    #   best_epoch = epoch\n",
        "\n",
        "    # print(\n",
        "    #   \"dev accuracy:{}\\ttime:{:.2f}s\"\n",
        "    #   .format(dev_accuracy, time.time() - t0)\n",
        "    # )\n",
        "\n",
        "    _, _, _, _, _, _, _, train_accuracy = _evaluate(train_loader, model)\n",
        "\n",
        "    print(\n",
        "      \"train accuracy:{}\\ttime:{:.2f}s\"\n",
        "      .format(train_accuracy, time.time() - t0)\n",
        "    )\n",
        "\n",
        "  #model.load_state_dict(best_state_dict)\n",
        "  if model_path:\n",
        "    print(\"Best dev epoch {} and accuracy {}\".format(best_epoch, best_dev_accuracy))\n",
        "    torch.save(model.state_dict(), MODELS_DIR + model_path)\n",
        "    if params_path:\n",
        "      with open(MODELS_DIR + params_path, 'wb') as f:\n",
        "        pickle.dump(params, f)\n",
        "\n",
        "  #evaluate_model([first_batch] * 1, model, \"train\")\n",
        "  evaluate_model(train_loader, model, \"train\")\n",
        "  #evaluate_model(dev_loader, model, \"dev\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-anSMTog1LSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = load_data(\n",
        "  DATA_DIR + \"/numeral/train.data.npy\",\n",
        "  DATA_DIR + \"/numeral/train.length.npy\",\n",
        "  DATA_DIR + \"/numeral/train.labels.npy\"\n",
        ")\n",
        "dev_data = load_data(\n",
        "  DATA_DIR + \"/numeral/dev.data.npy\",\n",
        "  DATA_DIR + \"/numeral/dev.length.npy\",\n",
        "  DATA_DIR + \"/numeral/dev.labels.npy\"\n",
        ")\n",
        "test_data = load_data(\n",
        "  DATA_DIR + \"/numeral/test.data.npy\",\n",
        "  DATA_DIR + \"/numeral/test.length.npy\",\n",
        "  DATA_DIR + \"/numeral/test.labels.npy\"\n",
        ")\n",
        "\n",
        "alphabet = {}\n",
        "with open(DATA_DIR + '/numeral/alphabet.dict', 'rb') as f:\n",
        "  alphabet = pickle.load(f)\n",
        "\n",
        "params = {\n",
        "  'batch_size': 3,\n",
        "  'num_epochs': 100,\n",
        "  'num_embeddings': len(alphabet),\n",
        "  'embedding_dim': 3,\n",
        "  'mode': 'rnn',\n",
        "  'nonlinearity': 'tanh',\n",
        "  'hidden_size': 100,\n",
        "  'bias': True\n",
        "  # 'number_of_states': 5,\n",
        "  # 'temperature': 0.0001,\n",
        "}\n",
        "\n",
        "train_loader = utils.data.DataLoader(\n",
        "  NLDataset(train_data), batch_size=params[\"batch_size\"], shuffle = True\n",
        ")\n",
        "dev_loader = utils.data.DataLoader(\n",
        "  NLDataset(dev_data), batch_size=params[\"batch_size\"]\n",
        ")\n",
        "test_loader = utils.data.DataLoader(\n",
        "  NLDataset(test_data), batch_size=params[\"batch_size\"]\n",
        ")\n",
        "\n",
        "model = NLNN(params)\n",
        "train_model(\n",
        "  model,\n",
        "  params=params,\n",
        "  params_path=\"/numeral/gru.model.params\",\n",
        "  model_path=\"/numeral/gru.model.pt\",\n",
        "  train_loader=train_loader, dev_loader=dev_loader\n",
        ")\n",
        "#evaluate_model(test_loader, model, \"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuAHR09WBXtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(params_path=None, model_path=None):\n",
        "  with open(DATA_DIR + params_path, 'rb') as f:\n",
        "    params = pickle.load(f)\n",
        "  model = NLNN(params)\n",
        "  model.load_state_dict(torch.load(DATA_DIR + model_path))\n",
        "  model.to(device)\n",
        "  return model, params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TmNV_L7ClAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def draw(transitions, is_final, start_state, pdf):\n",
        "\n",
        "  states = set()\n",
        "  for transition in transitions:\n",
        "    q_1, l, q_2 = transition\n",
        "    states.add(q_1)\n",
        "    states.add(q_2)\n",
        "\n",
        "  g = Digraph('G', filename=DATA_DIR + pdf, format='pdf')\n",
        "  g.attr(rankdir='LR', size='8,5')\n",
        "\n",
        "  for state in states:\n",
        "\n",
        "    if is_final[state] == 1:\n",
        "      if state == start_state:\n",
        "        g.attr('node', shape='doublecircle', style='filled', color='gray80')\n",
        "      else:\n",
        "        g.attr('node', shape='doublecircle', style='filled', color='gray80')\n",
        "      g.node(str(state))\n",
        "    else:\n",
        "      if state == start_state:\n",
        "        g.attr('node', shape='doubleoctagon', style='filled', color='gray80')\n",
        "      else:\n",
        "        g.attr('node', shape='circle', style='filled', color='gray80')\n",
        "      g.node(str(state))\n",
        "\n",
        "    g.attr('node', shape='point', color=\"black\")\n",
        "\n",
        "  g.edge('', str(start_state), label='', color=\"black\")\n",
        "\n",
        "  for transition in transitions:\n",
        "    q_1, l, q_2 = transition\n",
        "    g.edge(str(q_1), str(q_2), label=str(l))\n",
        "\n",
        "  g.render() \n",
        "  print('DFA extracted at: ' + str(DATA_DIR + pdf + \".pdf\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96NiN7fMAnAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, params = load_model(\n",
        "    params_path=\"/model/srrnn-light/model.params\",\n",
        "    model_path=\"/model/srrnn-light/model.pt\"\n",
        ")\n",
        "print (params)\n",
        "evaluate_model(train_loader, model, \"train\")\n",
        "evaluate_model(dev_loader, model, \"dev\")\n",
        "dev_loader = utils.data.DataLoader(\n",
        "  NLDataset(train_data), batch_size=1\n",
        ")\n",
        "\n",
        "# inv_alphabet = { v : k for k, v in alphabet.items() }\n",
        "\n",
        "# transitions = set()\n",
        "# for data in dev_loader:\n",
        "#   x, length = data['x'], data['length']\n",
        "#   #print (x, length)\n",
        "#   #print (data['y'].item(), \"\".join([inv_alphabet[c] for c in data['x'][0].cpu().numpy()[:data['length'][0]]]))\n",
        "#   softmax_output, transition_probabilities = model(x, length, return_probabilities=True)\n",
        "#   transition_probabilities, _ = nn.utils.rnn.pad_packed_sequence(transition_probabilities, batch_first=True)\n",
        "#   first = x[0]\n",
        "#   prev_state = 0\n",
        "#   for t in range(length[0]):\n",
        "#     l = inv_alphabet[first[t].item()]\n",
        "#     next_state = torch.argmax(transition_probabilities[0, t, ]).item() + 1\n",
        "#     transitions.add((prev_state, l, next_state))\n",
        "#     prev_state = next_state\n",
        "\n",
        "# h_0 = torch.zeros((1, params['hidden_size']), device=device)\n",
        "# is_final = model.softmax(model.linear(torch.cat((h_0, model.rnn.states)))).argmax(dim=1).cpu().numpy()\n",
        "# draw(transitions, is_final, 0, \"/model.35.train\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}