{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "State Regularized RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlNV3LjNQO3qNPlS3jDNGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelly-hateva/tardis/blob/master/notebooks/State_Regularized_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y0Pyq0G0A4W",
        "colab_type": "text"
      },
      "source": [
        "Prerequisities: Access data in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvCTwouDz-zs",
        "colab_type": "code",
        "outputId": "7803dd70-456e-4e7a-abd3-9781f81ee685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "MOUNT_POINT = \"/content/drive/\"\n",
        "DATA_DIR = MOUNT_POINT + \"My Drive/Colab Notebooks/Thesis-Data\"\n",
        "MODELS_DIR = MOUNT_POINT + \"My Drive/Colab Notebooks/Thesis-Models\"\n",
        "drive.mount(MOUNT_POINT)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQZ5n1R0aWe",
        "colab_type": "text"
      },
      "source": [
        "Import libraries, set random seed and device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u56lsr5U0W7h",
        "colab_type": "code",
        "outputId": "ba7819c7-bf5a-44f1-f7d8-997fb66f5eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import copy\n",
        "\n",
        "import numpy\n",
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "\n",
        "def seed_torch(seed=666):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  numpy.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_torch()\n",
        "\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ed6ar_Jc8dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmebY44nka2",
        "colab_type": "text"
      },
      "source": [
        "Define State Regularized RNN Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KalxGpXspeNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SRRNN(nn.Module):\n",
        "\n",
        "  r\"\"\" https://arxiv.org/pdf/1901.08817.pdf\n",
        "       https://github.com/deepsemantic/sr-rnns\n",
        "  Applies a State Regularized RNN to an input sequence.\n",
        "\n",
        "  For each element in the input sequence computes the following function:\n",
        "\n",
        "    .. math::\n",
        "      \\begin{array}{ll} \\\\\n",
        "        r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
        "        z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
        "        n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
        "        h_t' = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
        "        \\alpha_{i} = \\frac{\\exp(- \\Vert{h_t' - s_i}\\Vert)}{\\sum_{i=1}^{k} \\exp(- \\Vert{h_t' - s_i}\\Vert)}\n",
        "        h_t = {\\sum_{i=1}^{k} \\alpha_{i} s_i}\n",
        "      \\end{array}\n",
        "\n",
        "  where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\n",
        "  at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\n",
        "  at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n",
        "  :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n",
        "  :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
        "  :math:`\\{s_1, s_2, ..., s_k\\}` are the k learnable states. \n",
        "  :math:`\\alpha_{i}` is the probability of the RNN to transition to state i\n",
        "  given the vector :math:`h_t'` for which we write :math:`p_{h_t'}(i) = \\alpha_{i}`\n",
        "\n",
        "    Args:\n",
        "        input_size: The number of expected features in the input `x`\n",
        "        hidden_size: The number of features in the hidden state `h`\n",
        "        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
        "            Default: ``True``\n",
        "        number_of_states: The number of learnable finite states\n",
        "\n",
        "    Inputs: input, h_0\n",
        "        - **input** of shape `(batch, seq_len, input_size)`:\n",
        "          tensor containing the features of the input sequence.\n",
        "          The input can also be a packed variable length sequence.\n",
        "          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
        "          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
        "        - **h_0** of shape `(batch, hidden_size)`: tensor\n",
        "          containing the initial hidden state for each element in the batch.\n",
        "\n",
        "          If `h_0` is not provided, it defaults to zero.\n",
        "\n",
        "    Outputs: output, h_n\n",
        "        - **output** of shape `(batch, seq_len, hidden_size)`: tensor\n",
        "          containing the output features `(h_t)` from the RNN for each `t`.\n",
        "          If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
        "          given as the input, the output will also be a packed sequence.\n",
        "        - **h_n** of shape `(batch, hidden_size)`: tensor\n",
        "          containing the hidden state for `t = seq_len`.\n",
        "\n",
        "    Attributes:\n",
        "        weight_ih : the learnable input-hidden weights\n",
        "            (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)`\n",
        "        weight_hh : the learnable hidden-hidden weights\n",
        "            (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n",
        "        bias_ih : the learnable input-hidden bias\n",
        "            (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n",
        "        bias_hh : the learnable hidden-hidden bias\n",
        "            (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n",
        "        states: the learnable finite number of states, of shape\n",
        "            `(number_of_states, hidden_size)`\n",
        "\n",
        "    .. note::\n",
        "        The states are initialized from :math:`\\mathcal{U}(-0.05, 0.05)`\n",
        "        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
        "        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
        "\n",
        "    Examples::\n",
        "\n",
        "        >>> rnn = SRRNN(10, 20, 35, bias=False)\n",
        "        >>> input = torch.randn(6, 3, 10)\n",
        "        >>> h_0 = torch.randn(6, 20)\n",
        "        >>> output, h_n = rnn(input, h_0)\n",
        "    \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "    self, input_size, hidden_size, rnn_cell=nn.RNNCell, bias=True,\n",
        "    nonlinearity='tanh', number_of_states=None, temperature=1.00\n",
        "  ):\n",
        "    super(SRRNN, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "    self.number_of_gates = 3 if rnn_cell is nn.GruCell else 1\n",
        "    self.rnn_cell = rnn_cell(\n",
        "      self.input_size,\n",
        "      self.hidden_size,\n",
        "      bias=self.bias,\n",
        "      nonlinearity=nonlinearity\n",
        "    )\n",
        "\n",
        "    self.stohastic_component = False\n",
        "\n",
        "    if number_of_states:\n",
        "      self.stohastic_component = True\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "      self.number_of_states = number_of_states\n",
        "      self.states = nn.Parameter(\n",
        "        torch.Tensor(\n",
        "            self.number_of_states, self.hidden_size\n",
        "        )\n",
        "      )\n",
        "      self.temperature = temperature\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for hh, ih in zip(\n",
        "      self.rnn_cell.weight_hh.chunk(self.number_of_gates, 0),\n",
        "      self.rnn_cell.weight_ih.chunk(self.number_of_gates, 0)\n",
        "    ):\n",
        "      nn.init.orthogonal_(hh)\n",
        "      nn.init.orthogonal_(ih)\n",
        "\n",
        "    if self.bias:\n",
        "      nn.init.zeros_(self.rnn_cell.bias_ih)\n",
        "      nn.init.zeros_(self.rnn_cell.bias_hh)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      nn.init.uniform_(self.states, a=-0.1, b=0.1)\n",
        "\n",
        "  def extra_repr(self):\n",
        "    s = 'input_size={input_size}, ' \\\n",
        "      'hidden_size={hidden_size}'\n",
        "    if self.stohastic_component:\n",
        "      s += ', number_of_states={number_of_states}, ' \\\n",
        "        'temperature={temperature}'\n",
        "    return s.format(**self.__dict__)\n",
        "\n",
        "  def permute_hidden(self, hidden, permutation, dim=0):\n",
        "    if permutation is None:\n",
        "      return hidden\n",
        "    return hidden.index_select(dim, permutation)\n",
        "\n",
        "  def forward(self, input, h_0=None):\n",
        "    orig_input = input\n",
        "\n",
        "    if isinstance(orig_input, nn.utils.rnn.PackedSequence):\n",
        "      input, batch_sizes, sorted_indices, unsorted_indices = input\n",
        "      max_batch_size = int(batch_sizes[0])\n",
        "    else:\n",
        "      max_batch_size, sorted_indices = input.size(0), None\n",
        "\n",
        "    if h_0 is None:\n",
        "      h_0 = torch.zeros(\n",
        "        max_batch_size, self.hidden_size, dtype=input.dtype, device=input.device\n",
        "      )\n",
        "      #  h_0 = self.states[0].expand(max_batch_size, -1)\n",
        "    else:\n",
        "      # Each batch of the hidden state should match the input sequence that\n",
        "      # the user believes he/she is passing in.\n",
        "      h_0 = self.permute_hidden(h_0, sorted_indices)\n",
        "\n",
        "    if isinstance(orig_input, nn.utils.rnn.PackedSequence):\n",
        "      output, hidden, transition_probabilities = self.forward_packed(input, batch_sizes, h_0)\n",
        "\n",
        "      if self.stohastic_component:\n",
        "        transition_probabilities = nn.utils.rnn.PackedSequence(\n",
        "          transition_probabilities, batch_sizes, sorted_indices, unsorted_indices\n",
        "        )\n",
        "\n",
        "      hidden = self.permute_hidden(hidden, unsorted_indices)\n",
        "      output = nn.utils.rnn.PackedSequence(\n",
        "        output, batch_sizes, sorted_indices, unsorted_indices\n",
        "      )\n",
        "\n",
        "      return output, hidden, transition_probabilities\n",
        "\n",
        "    return self.forward_tensor(input, h_0)\n",
        "\n",
        "  def forward_tensor(self, input, h_0):\n",
        "    output, h_t = [], h_0\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      transition_probabilities = []\n",
        "\n",
        "    for t in range(input.size(1)):\n",
        "      result = self.forward_impl(input[:,t,:], h_t)\n",
        "      if self.stohastic_component:\n",
        "        transition_probs, h_t = result\n",
        "        transition_probabilities.append(transition_probs)\n",
        "      else:\n",
        "        h_t = result\n",
        "      output.append(h_t)\n",
        "\n",
        "    output = torch.stack(output).permute(1, 0, 2)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      return output, h_t, torch.stack(transition_probabilities).permute(1, 0, 2)\n",
        "    return output, h_t, None\n",
        "\n",
        "  def forward_packed(self, input, batch_sizes, h_0):\n",
        "    output, h_n, t, h_t = [], [], 0, h_0\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      transition_probabilities = []\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "      batch_size = int(batch_size)\n",
        "\n",
        "      h_t, h_n_ = h_t[:batch_size], h_t[batch_size:]\n",
        "      h_n.append(h_n_)\n",
        "      result = self.forward_impl(input[t : t + batch_size], h_t)\n",
        "\n",
        "      if self.stohastic_component:\n",
        "        transition_probs, h_t = result\n",
        "        transition_probabilities.append(transition_probs)\n",
        "      else:\n",
        "        h_t = result\n",
        "\n",
        "      output.append(h_t)\n",
        "      t += batch_size\n",
        "\n",
        "    h_n.append(h_t)\n",
        "    h_n.reverse()\n",
        "\n",
        "    output, h_n = torch.cat(output), torch.cat(h_n)\n",
        "\n",
        "    if self.stohastic_component:\n",
        "      return output, h_n, torch.cat(transition_probabilities)\n",
        "    return output, h_n, None\n",
        "\n",
        "  def forward_impl(self, input, h_t):\n",
        "    h_t_ = self.rnn_cell(input, h_t)\n",
        "    if self.stohastic_component:\n",
        "      transition_probs = self.softmax(\n",
        "        (self.states * h_t_.unsqueeze(1)).sum(-1) / self.temperature\n",
        "      )\n",
        "      return transition_probs, torch.matmul(transition_probs, self.states)\n",
        "    return h_t_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjEpfYqHnnzv",
        "colab_type": "text"
      },
      "source": [
        "Smoke Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbH4_rwho4wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  for _ in range(1024):\n",
        "    batch_size = random.randint(1, 15)\n",
        "    seq_length = random.randint(1, 15)\n",
        "    input_size = random.randint(1, 5)\n",
        "    hidden_size = random.randint(1, 5)\n",
        "    number_of_states = random.randint(1, 15)\n",
        "\n",
        "    input = torch.rand(batch_size, seq_length, input_size).to(device)\n",
        "    h_0 = torch.rand(batch_size, hidden_size).to(device)\n",
        "\n",
        "    lengths = torch.randint(1, seq_length + 1, (batch_size,)).to(device)\n",
        "    packed_sequence = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "      input, lengths, batch_first=True, enforce_sorted=False\n",
        "    )\n",
        "\n",
        "    # without stohastic component\n",
        "    model = SRRNN(input_size, hidden_size)\n",
        "    model.to(device)\n",
        "\n",
        "    output, h_n, _ = model(input, h_0)\n",
        "\n",
        "    assert h_n.size() == (batch_size, hidden_size)\n",
        "    assert output.size() == (batch_size, seq_length, hidden_size)\n",
        "\n",
        "    output_packed, h_n_packed, _ = model(packed_sequence, h_0)\n",
        "\n",
        "    assert h_n_packed.size() == (batch_size, hidden_size)\n",
        "    assert output_packed.data.size() == (lengths.sum().item(), hidden_size)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      assert torch.allclose(h_n_packed[i,:], output[i, lengths[i].item() - 1, :], atol=1e-07)\n",
        "\n",
        "    # with stohastic component\n",
        "    model = SRRNN(input_size, hidden_size, number_of_states)\n",
        "    model.to(device)\n",
        "\n",
        "    output, h_n, transition_probabilities = model(input, h_0)\n",
        "\n",
        "    assert h_n.size() == (batch_size, hidden_size)\n",
        "    assert output.size() == (batch_size, seq_length, hidden_size)\n",
        "    assert transition_probabilities.size() == (batch_size, seq_length, number_of_states)\n",
        "\n",
        "    output_packed, h_n_packed, transition_probabilities_packed = model(packed_sequence, h_0)\n",
        "\n",
        "    assert h_n_packed.size() == (batch_size, hidden_size)\n",
        "    assert output_packed.data.size() == (lengths.sum().item(), hidden_size)\n",
        "    assert transition_probabilities_packed.data.size() == (lengths.sum().item(), number_of_states)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      assert torch.allclose(h_n_packed[i,:], output[i, lengths[i].item() - 1, :], atol=1e-07)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAaRQ6-0LOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLNN(nn.Module):\n",
        "\n",
        "  def __init__(self, params):\n",
        "    super(NLNN, self).__init__()\n",
        "\n",
        "    # + 1 because of the padding with 0s\n",
        "    num_embeddings = params['alphabet_size'] + 1\n",
        "\n",
        "    if 'embedding_size' in params:\n",
        "      self.embeddings = nn.Embedding(\n",
        "        num_embeddings,\n",
        "        params['embedding_size'],\n",
        "        padding_idx = 0\n",
        "      )\n",
        "      nn.init.xavier_uniform_(self.embeddings.weight.data, gain=0.01)\n",
        "      input_size = params['embedding_size']\n",
        "    else:\n",
        "      # one hot encoding\n",
        "      self.embeddings = nn.Embedding(\n",
        "          num_embeddings,\n",
        "          num_embeddings,\n",
        "          padding_idx = 0\n",
        "      )\n",
        "      nn.init.eye_(self.embeddings.weight.data)\n",
        "      self.embeddings.weight.requires_grad = False\n",
        "      input_size = num_embeddings\n",
        "\n",
        "    if 'number_of_states' in params:\n",
        "      self.rnn = SRRNN(\n",
        "        input_size, params['hidden_size'], params['number_of_states'],\n",
        "        bias=params['rnn_bias'], temperature=params['temperature']\n",
        "      )\n",
        "    else:\n",
        "      self.rnn = SRRNN(\n",
        "        input_size, params['hidden_size'], bias=params['rnn_bias']\n",
        "      )\n",
        "\n",
        "    self.linear = nn.Linear(\n",
        "      in_features=params['hidden_size'], out_features=2, bias=True\n",
        "    )\n",
        "    nn.init.xavier_uniform_(self.linear.weight, gain=0.01)\n",
        "    nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x, length, return_probabilities=False):\n",
        "    embedding_output = self.embeddings(x)\n",
        "    packed_sequence = nn.utils.rnn.pack_padded_sequence(\n",
        "      embedding_output, length, batch_first=True, enforce_sorted=False\n",
        "    )\n",
        "    rnn_output, h_n, transition_probs = self.rnn(packed_sequence)\n",
        "    linear_output = self.linear(h_n)\n",
        "    softmax_output = self.softmax(linear_output)\n",
        "\n",
        "    if return_probabilities:\n",
        "      return softmax_output, transition_probs\n",
        "\n",
        "    return softmax_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOiy1Kys02Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLDataset(utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, dataset):\n",
        "    data, length, labels = dataset\n",
        "    self.data = torch.tensor(data).long().to(device)\n",
        "    self.length = torch.tensor(length).long().to(device)\n",
        "    self.labels = torch.tensor(labels).long().to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\n",
        "      'x': self.data[idx],\n",
        "      'length': self.length[idx],\n",
        "      'y': self.labels[idx]\n",
        "    }\n",
        "\n",
        "def load_data(filename_data, filename_length, filename_labels):\n",
        "  return numpy.load(filename_data, allow_pickle=True), \\\n",
        "    numpy.load(filename_length, allow_pickle=True), \\\n",
        "    numpy.load(filename_labels, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUX8FKwB1SyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __evaluate(predictions, labels):\n",
        "  assert(len(predictions) == len(labels))\n",
        "\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    if label == 1:\n",
        "      if prediction == 1:\n",
        "        tp += 1\n",
        "      else:\n",
        "        fn += 1\n",
        "    else:\n",
        "      if prediction == 1:\n",
        "        fp += 1\n",
        "      else:\n",
        "        tn += 1\n",
        "\n",
        "  if tp == 0:\n",
        "    if fn == 0 and fp == 0:\n",
        "      pr, r, f1 = 1, 1, 1\n",
        "    else:\n",
        "      pr, r, f1 = 0, 0, 0\n",
        "  else:\n",
        "    pr = tp / (tp + fp)\n",
        "    r = tp / (tp + fn)\n",
        "    f1 = 2 * ((pr * r) / (pr + r))\n",
        "\n",
        "  accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "  return tp, tn, fp, fn, pr, r, f1, accuracy\n",
        "\n",
        "def _evaluate(data_loader, model):\n",
        "  model.eval()\n",
        "\n",
        "  predictions, labels = [], []\n",
        "\n",
        "  for data in data_loader:\n",
        "    result = model(data['x'], data['length'])\n",
        "    argmax = result.argmax(dim=1).cpu().numpy()\n",
        "    predictions.extend(list(argmax))\n",
        "    labels.extend(list(data['y'].cpu().numpy()))\n",
        "\n",
        "  return __evaluate(predictions, labels)\n",
        "\n",
        "def evaluate_model(data_loader, model, set_name):\n",
        "  tp, tn, fp, fn, pr, r, f1, acc = _evaluate(data_loader, model)\n",
        "  print(\"{} : TP : {} TN : {} FP : {} FN : {} Pr : {} R : {} F1: {} ACC : {} \".format(\n",
        "    set_name, tp, tn, fp, fn, pr, r, f1, acc\n",
        "  ))\n",
        "\n",
        "def model_summary(model):\n",
        "  print (model)\n",
        "  print()\n",
        "\n",
        "  print(\"Trainable parameters:\")\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      print (\" \", name)\n",
        "  print()\n",
        "\n",
        "  number_of_trainable_parameters = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        "  )\n",
        "  print(\"Number of trainable parameters {0:,}\".format(\n",
        "    number_of_trainable_parameters\n",
        "  ))\n",
        "  print()\n",
        "\n",
        "def train_model(\n",
        "    model, params=None, params_path=None, model_path=None,\n",
        "    train_loader=None, dev_loader=None\n",
        "):\n",
        "  model.to(device)\n",
        "  model_summary(model)\n",
        "\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  best_dev_accuracy, best_state_dict, best_epoch = 0, dict(), -1\n",
        "\n",
        "  # first_batch = next(iter(train_loader))\n",
        "  # print (first_batch)\n",
        "\n",
        "  for epoch in range(params['num_epochs']):\n",
        "    print('Epoch {}/{} : '.format(epoch, params['num_epochs']))\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train() # set the model to training mode\n",
        "    #for data in [first_batch] * 1:\n",
        "    for data in train_loader:\n",
        "      model.zero_grad()\n",
        "      predictions = model(data['x'], data['length'])\n",
        "      batch_loss = loss_function(predictions, data['y'])\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    _, _, _, _, _, _, _, dev_accuracy = _evaluate(dev_loader, model)\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "      best_dev_accuracy = dev_accuracy\n",
        "      best_state_dict = copy.deepcopy(model.state_dict())\n",
        "      best_epoch = epoch\n",
        "\n",
        "    print(\n",
        "      \"dev accuracy:{}\\ttime:{:.2f}s\"\n",
        "      .format(dev_accuracy, time.time() - t0)\n",
        "    )\n",
        "\n",
        "    _, _, _, _, _, _, _, train_accuracy = _evaluate(train_loader, model)\n",
        "\n",
        "    print(\n",
        "      \"train accuracy:{}\\ttime:{:.2f}s\"\n",
        "      .format(train_accuracy, time.time() - t0)\n",
        "    )\n",
        "\n",
        "  model.load_state_dict(best_state_dict)\n",
        "  if model_path:\n",
        "    print(\"Best dev epoch {} and accuracy {}\".format(best_epoch, best_dev_accuracy))\n",
        "    torch.save(model.state_dict(), MODELS_DIR + model_path)\n",
        "    if params_path:\n",
        "      with open(MODELS_DIR + params_path, 'wb') as f:\n",
        "        pickle.dump(params, f)\n",
        "\n",
        "  #evaluate_model([first_batch] * 1, model, \"train\")\n",
        "  evaluate_model(train_loader, model, \"train\")\n",
        "  evaluate_model(dev_loader, model, \"dev\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-anSMTog1LSb",
        "colab_type": "code",
        "outputId": "2f99ba95-8e5c-4195-b277-8a7c88b16a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data = load_data(\n",
        "  DATA_DIR + \"/numeral/train.data.npy\",\n",
        "  DATA_DIR + \"/numeral/train.length.npy\",\n",
        "  DATA_DIR + \"/numeral/train.labels.npy\"\n",
        ")\n",
        "dev_data = load_data(\n",
        "  DATA_DIR + \"/numeral/dev.data.npy\",\n",
        "  DATA_DIR + \"/numeral/dev.length.npy\",\n",
        "  DATA_DIR + \"/numeral/dev.labels.npy\"\n",
        ")\n",
        "test_data = load_data(\n",
        "  DATA_DIR + \"/numeral/test.data.npy\",\n",
        "  DATA_DIR + \"/numeral/test.length.npy\",\n",
        "  DATA_DIR + \"/numeral/test.labels.npy\"\n",
        ")\n",
        "\n",
        "alphabet = {}\n",
        "with open(DATA_DIR + '/numeral/alphabet.dict', 'rb') as f:\n",
        "  alphabet = pickle.load(f)\n",
        "\n",
        "params = {\n",
        "  'batch_size': 3,\n",
        "  'num_epochs': 100,\n",
        "  'alphabet_size': len(alphabet),\n",
        "  'embedding_size': 3,\n",
        "  'hidden_size': 100,\n",
        "  'rnn_bias': True\n",
        "  # 'number_of_states': 5,\n",
        "  # 'temperature': 0.0001,\n",
        "}\n",
        "\n",
        "train_loader = utils.data.DataLoader(\n",
        "  NLDataset(train_data), batch_size=params[\"batch_size\"], shuffle = True\n",
        ")\n",
        "dev_loader = utils.data.DataLoader(\n",
        "  NLDataset(dev_data), batch_size=params[\"batch_size\"]\n",
        ")\n",
        "test_loader = utils.data.DataLoader(\n",
        "  NLDataset(test_data), batch_size=params[\"batch_size\"]\n",
        ")\n",
        "\n",
        "model = NLNN(params)\n",
        "train_model(\n",
        "  model,\n",
        "  params=params,\n",
        "  params_path=\"/numeral/gru.model.params\",\n",
        "  model_path=\"/numeral/gru.model.pt\",\n",
        "  train_loader=train_loader, dev_loader=dev_loader\n",
        ")\n",
        "evaluate_model(test_loader, model, \"test\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLNN(\n",
            "  (embeddings): Embedding(14, 3, padding_idx=0)\n",
            "  (rnn): SRRNN(\n",
            "    input_size=3, hidden_size=100\n",
            "    (rnn_cell): GRUCell(3, 100)\n",
            "  )\n",
            "  (linear): Linear(in_features=100, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "Trainable parameters:\n",
            "  embeddings.weight\n",
            "  rnn.rnn_cell.weight_ih\n",
            "  rnn.rnn_cell.weight_hh\n",
            "  rnn.rnn_cell.bias_ih\n",
            "  rnn.rnn_cell.bias_hh\n",
            "  linear.weight\n",
            "  linear.bias\n",
            "\n",
            "Number of trainable parameters 31,744\n",
            "\n",
            "Epoch 0/100 : \n",
            "dev accuracy:0.4\ttime:0.23s\n",
            "train accuracy:0.5\ttime:0.29s\n",
            "Epoch 1/100 : \n",
            "dev accuracy:0.4\ttime:0.23s\n",
            "train accuracy:0.5\ttime:0.29s\n",
            "Epoch 2/100 : \n",
            "dev accuracy:0.6\ttime:0.17s\n",
            "train accuracy:0.5\ttime:0.22s\n",
            "Epoch 3/100 : \n",
            "dev accuracy:0.6\ttime:0.17s\n",
            "train accuracy:0.5\ttime:0.22s\n",
            "Epoch 4/100 : \n",
            "dev accuracy:0.6\ttime:0.16s\n",
            "train accuracy:0.5\ttime:0.21s\n",
            "Epoch 5/100 : \n",
            "dev accuracy:0.6\ttime:0.19s\n",
            "train accuracy:0.5\ttime:0.23s\n",
            "Epoch 6/100 : \n",
            "dev accuracy:0.6\ttime:0.21s\n",
            "train accuracy:0.5\ttime:0.25s\n",
            "Epoch 7/100 : \n",
            "dev accuracy:0.6\ttime:0.17s\n",
            "train accuracy:0.5\ttime:0.21s\n",
            "Epoch 8/100 : \n",
            "dev accuracy:0.2\ttime:0.16s\n",
            "train accuracy:0.5375\ttime:0.22s\n",
            "Epoch 9/100 : \n",
            "dev accuracy:0.3\ttime:0.22s\n",
            "train accuracy:0.575\ttime:0.29s\n",
            "Epoch 10/100 : \n",
            "dev accuracy:0.4\ttime:0.21s\n",
            "train accuracy:0.5125\ttime:0.26s\n",
            "Epoch 11/100 : \n",
            "dev accuracy:0.8\ttime:0.17s\n",
            "train accuracy:0.4625\ttime:0.21s\n",
            "Epoch 12/100 : \n",
            "dev accuracy:0.5\ttime:0.16s\n",
            "train accuracy:0.5125\ttime:0.21s\n",
            "Epoch 13/100 : \n",
            "dev accuracy:0.2\ttime:0.18s\n",
            "train accuracy:0.5375\ttime:0.24s\n",
            "Epoch 14/100 : \n",
            "dev accuracy:0.6\ttime:0.17s\n",
            "train accuracy:0.5\ttime:0.22s\n",
            "Epoch 15/100 : \n",
            "dev accuracy:0.4\ttime:0.16s\n",
            "train accuracy:0.525\ttime:0.21s\n",
            "Epoch 16/100 : \n",
            "dev accuracy:0.2\ttime:0.16s\n",
            "train accuracy:0.55\ttime:0.21s\n",
            "Epoch 17/100 : \n",
            "dev accuracy:0.2\ttime:0.16s\n",
            "train accuracy:0.5625\ttime:0.22s\n",
            "Epoch 18/100 : \n",
            "dev accuracy:0.2\ttime:0.19s\n",
            "train accuracy:0.5375\ttime:0.26s\n",
            "Epoch 19/100 : \n",
            "dev accuracy:0.2\ttime:0.21s\n",
            "train accuracy:0.5375\ttime:0.25s\n",
            "Epoch 20/100 : \n",
            "dev accuracy:0.1\ttime:0.16s\n",
            "train accuracy:0.6\ttime:0.21s\n",
            "Epoch 21/100 : \n",
            "dev accuracy:0.2\ttime:0.16s\n",
            "train accuracy:0.5625\ttime:0.21s\n",
            "Epoch 22/100 : \n",
            "dev accuracy:0.1\ttime:0.16s\n",
            "train accuracy:0.575\ttime:0.21s\n",
            "Epoch 23/100 : \n",
            "dev accuracy:0.2\ttime:0.18s\n",
            "train accuracy:0.55\ttime:0.24s\n",
            "Epoch 24/100 : \n",
            "dev accuracy:0.2\ttime:0.18s\n",
            "train accuracy:0.575\ttime:0.23s\n",
            "Epoch 25/100 : \n",
            "dev accuracy:0.1\ttime:0.22s\n",
            "train accuracy:0.6\ttime:0.29s\n",
            "Epoch 26/100 : \n",
            "dev accuracy:0.1\ttime:0.19s\n",
            "train accuracy:0.6\ttime:0.24s\n",
            "Epoch 27/100 : \n",
            "dev accuracy:0.1\ttime:0.23s\n",
            "train accuracy:0.5875\ttime:0.30s\n",
            "Epoch 28/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.6125\ttime:0.21s\n",
            "Epoch 29/100 : \n",
            "dev accuracy:0.2\ttime:0.16s\n",
            "train accuracy:0.6\ttime:0.21s\n",
            "Epoch 30/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.6\ttime:0.21s\n",
            "Epoch 31/100 : \n",
            "dev accuracy:0.1\ttime:0.16s\n",
            "train accuracy:0.6125\ttime:0.21s\n",
            "Epoch 32/100 : \n",
            "dev accuracy:0.1\ttime:0.20s\n",
            "train accuracy:0.6125\ttime:0.26s\n",
            "Epoch 33/100 : \n",
            "dev accuracy:0.1\ttime:0.22s\n",
            "train accuracy:0.6\ttime:0.28s\n",
            "Epoch 34/100 : \n",
            "dev accuracy:0.1\ttime:0.19s\n",
            "train accuracy:0.6\ttime:0.24s\n",
            "Epoch 35/100 : \n",
            "dev accuracy:0.1\ttime:0.16s\n",
            "train accuracy:0.5875\ttime:0.21s\n",
            "Epoch 36/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.6375\ttime:0.23s\n",
            "Epoch 37/100 : \n",
            "dev accuracy:0.1\ttime:0.22s\n",
            "train accuracy:0.6\ttime:0.28s\n",
            "Epoch 38/100 : \n",
            "dev accuracy:0.1\ttime:0.22s\n",
            "train accuracy:0.6\ttime:0.27s\n",
            "Epoch 39/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.65\ttime:0.22s\n",
            "Epoch 40/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.65\ttime:0.22s\n",
            "Epoch 41/100 : \n",
            "dev accuracy:0.1\ttime:0.16s\n",
            "train accuracy:0.675\ttime:0.21s\n",
            "Epoch 42/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.7125\ttime:0.21s\n",
            "Epoch 43/100 : \n",
            "dev accuracy:0.3\ttime:0.16s\n",
            "train accuracy:0.6375\ttime:0.21s\n",
            "Epoch 44/100 : \n",
            "dev accuracy:0.1\ttime:0.18s\n",
            "train accuracy:0.7\ttime:0.22s\n",
            "Epoch 45/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.7375\ttime:0.22s\n",
            "Epoch 46/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.775\ttime:0.23s\n",
            "Epoch 47/100 : \n",
            "dev accuracy:0.3\ttime:0.22s\n",
            "train accuracy:0.7625\ttime:0.28s\n",
            "Epoch 48/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.775\ttime:0.21s\n",
            "Epoch 49/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.7875\ttime:0.22s\n",
            "Epoch 50/100 : \n",
            "dev accuracy:0.3\ttime:0.16s\n",
            "train accuracy:0.6875\ttime:0.21s\n",
            "Epoch 51/100 : \n",
            "dev accuracy:0.2\ttime:0.19s\n",
            "train accuracy:0.7125\ttime:0.25s\n",
            "Epoch 52/100 : \n",
            "dev accuracy:0.1\ttime:0.17s\n",
            "train accuracy:0.8125\ttime:0.22s\n",
            "Epoch 53/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.7875\ttime:0.21s\n",
            "Epoch 54/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.8125\ttime:0.22s\n",
            "Epoch 55/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.7875\ttime:0.24s\n",
            "Epoch 56/100 : \n",
            "dev accuracy:0.4\ttime:0.24s\n",
            "train accuracy:0.8625\ttime:0.28s\n",
            "Epoch 57/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.85\ttime:0.22s\n",
            "Epoch 58/100 : \n",
            "dev accuracy:0.3\ttime:0.17s\n",
            "train accuracy:0.8875\ttime:0.22s\n",
            "Epoch 59/100 : \n",
            "dev accuracy:0.2\ttime:0.17s\n",
            "train accuracy:0.8625\ttime:0.21s\n",
            "Epoch 60/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.8875\ttime:0.21s\n",
            "Epoch 61/100 : \n",
            "dev accuracy:0.3\ttime:0.17s\n",
            "train accuracy:0.8875\ttime:0.21s\n",
            "Epoch 62/100 : \n",
            "dev accuracy:0.4\ttime:0.16s\n",
            "train accuracy:0.8875\ttime:0.21s\n",
            "Epoch 63/100 : \n",
            "dev accuracy:0.3\ttime:0.17s\n",
            "train accuracy:0.825\ttime:0.21s\n",
            "Epoch 64/100 : \n",
            "dev accuracy:0.1\ttime:0.19s\n",
            "train accuracy:0.9\ttime:0.26s\n",
            "Epoch 65/100 : \n",
            "dev accuracy:0.3\ttime:0.22s\n",
            "train accuracy:0.8875\ttime:0.26s\n",
            "Epoch 66/100 : \n",
            "dev accuracy:0.3\ttime:0.16s\n",
            "train accuracy:0.8875\ttime:0.21s\n",
            "Epoch 67/100 : \n",
            "dev accuracy:0.3\ttime:0.16s\n",
            "train accuracy:0.8875\ttime:0.21s\n",
            "Epoch 68/100 : \n",
            "dev accuracy:0.3\ttime:0.16s\n",
            "train accuracy:0.9125\ttime:0.21s\n",
            "Epoch 69/100 : \n",
            "dev accuracy:0.3\ttime:0.22s\n",
            "train accuracy:0.9125\ttime:0.28s\n",
            "Epoch 70/100 : \n",
            "dev accuracy:0.4\ttime:0.22s\n",
            "train accuracy:0.9125\ttime:0.28s\n",
            "Epoch 71/100 : \n",
            "dev accuracy:0.3\ttime:0.18s\n",
            "train accuracy:0.9125\ttime:0.23s\n",
            "Epoch 72/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.9125\ttime:0.22s\n",
            "Epoch 73/100 : \n",
            "dev accuracy:0.3\ttime:0.23s\n",
            "train accuracy:0.9125\ttime:0.30s\n",
            "Epoch 74/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.925\ttime:0.21s\n",
            "Epoch 75/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.925\ttime:0.21s\n",
            "Epoch 76/100 : \n",
            "dev accuracy:0.4\ttime:0.18s\n",
            "train accuracy:0.9375\ttime:0.23s\n",
            "Epoch 77/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.925\ttime:0.23s\n",
            "Epoch 78/100 : \n",
            "dev accuracy:0.4\ttime:0.20s\n",
            "train accuracy:0.9\ttime:0.25s\n",
            "Epoch 79/100 : \n",
            "dev accuracy:0.4\ttime:0.18s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 80/100 : \n",
            "dev accuracy:0.4\ttime:0.18s\n",
            "train accuracy:0.9375\ttime:0.23s\n",
            "Epoch 81/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.21s\n",
            "Epoch 82/100 : \n",
            "dev accuracy:0.4\ttime:0.20s\n",
            "train accuracy:0.9375\ttime:0.24s\n",
            "Epoch 83/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 84/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.21s\n",
            "Epoch 85/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 86/100 : \n",
            "dev accuracy:0.4\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 87/100 : \n",
            "dev accuracy:0.4\ttime:0.21s\n",
            "train accuracy:0.95\ttime:0.28s\n",
            "Epoch 88/100 : \n",
            "dev accuracy:0.4\ttime:0.19s\n",
            "train accuracy:0.9375\ttime:0.24s\n",
            "Epoch 89/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 90/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.23s\n",
            "Epoch 91/100 : \n",
            "dev accuracy:0.5\ttime:0.20s\n",
            "train accuracy:0.9375\ttime:0.25s\n",
            "Epoch 92/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 93/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.21s\n",
            "Epoch 94/100 : \n",
            "dev accuracy:0.5\ttime:0.18s\n",
            "train accuracy:0.95\ttime:0.22s\n",
            "Epoch 95/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 96/100 : \n",
            "dev accuracy:0.5\ttime:0.22s\n",
            "train accuracy:0.9375\ttime:0.28s\n",
            "Epoch 97/100 : \n",
            "dev accuracy:0.5\ttime:0.18s\n",
            "train accuracy:0.9375\ttime:0.23s\n",
            "Epoch 98/100 : \n",
            "dev accuracy:0.5\ttime:0.17s\n",
            "train accuracy:0.9375\ttime:0.22s\n",
            "Epoch 99/100 : \n",
            "dev accuracy:0.5\ttime:0.19s\n",
            "train accuracy:0.9375\ttime:0.25s\n",
            "Best dev epoch 11 and accuracy 0.8\n",
            "train : TP : 17 TN : 20 FP : 20 FN : 23 Pr : 0.4594594594594595 R : 0.425 F1: 0.44155844155844154 ACC : 0.4625 \n",
            "dev : TP : 3 TN : 5 FP : 1 FN : 1 Pr : 0.75 R : 0.75 F1: 0.75 ACC : 0.8 \n",
            "test : TP : 3 TN : 3 FP : 1 FN : 3 Pr : 0.75 R : 0.5 F1: 0.6 ACC : 0.6 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuAHR09WBXtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(params_path=None, model_path=None):\n",
        "  with open(DATA_DIR + params_path, 'rb') as f:\n",
        "    params = pickle.load(f)\n",
        "  model = NLNN(params)\n",
        "  model.load_state_dict(torch.load(DATA_DIR + model_path))\n",
        "  model.to(device)\n",
        "  return model, params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TmNV_L7ClAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def draw(transitions, is_final, start_state, pdf):\n",
        "\n",
        "  states = set()\n",
        "  for transition in transitions:\n",
        "    q_1, l, q_2 = transition\n",
        "    states.add(q_1)\n",
        "    states.add(q_2)\n",
        "\n",
        "  g = Digraph('G', filename=DATA_DIR + pdf, format='pdf')\n",
        "  g.attr(rankdir='LR', size='8,5')\n",
        "\n",
        "  for state in states:\n",
        "\n",
        "    if is_final[state] == 1:\n",
        "      if state == start_state:\n",
        "        g.attr('node', shape='doublecircle', style='filled', color='gray80')\n",
        "      else:\n",
        "        g.attr('node', shape='doublecircle', style='filled', color='gray80')\n",
        "      g.node(str(state))\n",
        "    else:\n",
        "      if state == start_state:\n",
        "        g.attr('node', shape='doubleoctagon', style='filled', color='gray80')\n",
        "      else:\n",
        "        g.attr('node', shape='circle', style='filled', color='gray80')\n",
        "      g.node(str(state))\n",
        "\n",
        "    g.attr('node', shape='point', color=\"black\")\n",
        "\n",
        "  g.edge('', str(start_state), label='', color=\"black\")\n",
        "\n",
        "  for transition in transitions:\n",
        "    q_1, l, q_2 = transition\n",
        "    g.edge(str(q_1), str(q_2), label=str(l))\n",
        "\n",
        "  g.render() \n",
        "  print('DFA extracted at: ' + str(DATA_DIR + pdf + \".pdf\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96NiN7fMAnAA",
        "colab_type": "code",
        "outputId": "493a1668-7184-47bb-9714-d5b7e989b3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model, params = load_model(\n",
        "    params_path=\"/model/srrnn-light/model.params\",\n",
        "    model_path=\"/model/srrnn-light/model.pt\"\n",
        ")\n",
        "print (params)\n",
        "evaluate_model(train_loader, model, \"train\")\n",
        "evaluate_model(dev_loader, model, \"dev\")\n",
        "dev_loader = utils.data.DataLoader(\n",
        "  NLDataset(train_data), batch_size=1\n",
        ")\n",
        "\n",
        "# inv_alphabet = { v : k for k, v in alphabet.items() }\n",
        "\n",
        "# transitions = set()\n",
        "# for data in dev_loader:\n",
        "#   x, length = data['x'], data['length']\n",
        "#   #print (x, length)\n",
        "#   #print (data['y'].item(), \"\".join([inv_alphabet[c] for c in data['x'][0].cpu().numpy()[:data['length'][0]]]))\n",
        "#   softmax_output, transition_probabilities = model(x, length, return_probabilities=True)\n",
        "#   transition_probabilities, _ = nn.utils.rnn.pad_packed_sequence(transition_probabilities, batch_first=True)\n",
        "#   first = x[0]\n",
        "#   prev_state = 0\n",
        "#   for t in range(length[0]):\n",
        "#     l = inv_alphabet[first[t].item()]\n",
        "#     next_state = torch.argmax(transition_probabilities[0, t, ]).item() + 1\n",
        "#     transitions.add((prev_state, l, next_state))\n",
        "#     prev_state = next_state\n",
        "\n",
        "# h_0 = torch.zeros((1, params['hidden_size']), device=device)\n",
        "# is_final = model.softmax(model.linear(torch.cat((h_0, model.rnn.states)))).argmax(dim=1).cpu().numpy()\n",
        "# draw(transitions, is_final, 0, \"/model.35.train\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 2, 'num_epochs': 200, 'alphabet_size': 13, 'embedding_size': 3, 'hidden_size': 25, 'number_of_states': 35, 'temperature': 0.0001}\n",
            "train : TP : 34 TN : 9 FP : 31 FN : 6 Pr : 0.5230769230769231 R : 0.85 F1: 0.6476190476190476 ACC : 0.5375 \n",
            "dev : TP : 34 TN : 9 FP : 31 FN : 6 Pr : 0.5230769230769231 R : 0.85 F1: 0.6476190476190476 ACC : 0.5375 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}